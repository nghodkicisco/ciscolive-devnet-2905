#Run command to build the docker
docker build -f Dockerfile.arm -t vllm-cpu --shm-size=4g .


#Run below command to run the docker, add HF token and the repo path from where you want LLM to be downloaded
docker run -it --rm -p 8000:8000 \
--env "HUGGING_FACE_HUB_TOKEN=<HF Token>" \
vllm-cpu --model <Model repo path from HF eg. meta-llama/Llama-3.2-1B-Instruct> \
--dtype float16
